{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "035abcac-3d8c-4dd6-8722-a4e8abf2a1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.5 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3047, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3102, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3489, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3549, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/40/y2m0v2h9587d4pnsspl6bs6c0000gn/T/ipykernel_5456/2987838745.py\", line 17, in <module>\n",
      "    from src.trainer.trainer import Trainer\n",
      "  File \"/Users/larabastos/Desktop/uni/msc/q4/frmdl/fundamental-research-project/experiments/../src/trainer/trainer.py\", line 2, in <module>\n",
      "    from torch.utils.tensorboard import SummaryWriter\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torch/utils/tensorboard/__init__.py\", line 12, in <module>\n",
      "    from .writer import FileWriter, SummaryWriter\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torch/utils/tensorboard/writer.py\", line 19, in <module>\n",
      "    from ._embedding import get_embedding_info, make_mat, make_sprite, make_tsv, write_pbtxt\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torch/utils/tensorboard/_embedding.py\", line 10, in <module>\n",
      "    _HAS_GFILE_JOIN = hasattr(tf.io.gfile, \"join\")\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorboard/lazy.py\", line 65, in __getattr__\n",
      "    return getattr(load_once(self), attr_name)\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorboard/lazy.py\", line 97, in wrapper\n",
      "    cache[arg] = f(arg)\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorboard/lazy.py\", line 50, in load_once\n",
      "    module = load_fn()\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorboard/compat/__init__.py\", line 45, in tf\n",
      "    import tensorflow\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/__init__.py\", line 55, in <module>\n",
      "    from tensorflow._api.v2 import compat\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/_api/v2/compat/__init__.py\", line 8, in <module>\n",
      "    from tensorflow._api.v2.compat import v1\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/_api/v2/compat/v1/__init__.py\", line 30, in <module>\n",
      "    from tensorflow._api.v2.compat.v1 import compat\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py\", line 8, in <module>\n",
      "    from tensorflow._api.v2.compat.v1.compat import v1\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/_api/v2/compat/v1/compat/v1/__init__.py\", line 47, in <module>\n",
      "    from tensorflow._api.v2.compat.v1 import lite\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/_api/v2/compat/v1/lite/__init__.py\", line 9, in <module>\n",
      "    from tensorflow._api.v2.compat.v1.lite import experimental\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/_api/v2/compat/v1/lite/experimental/__init__.py\", line 8, in <module>\n",
      "    from tensorflow._api.v2.compat.v1.lite.experimental import authoring\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/_api/v2/compat/v1/lite/experimental/authoring/__init__.py\", line 8, in <module>\n",
      "    from tensorflow.lite.python.authoring.authoring import compatible # line: 263\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/lite/python/authoring/authoring.py\", line 42, in <module>\n",
      "    from tensorflow.lite.python import convert\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/lite/python/convert.py\", line 31, in <module>\n",
      "    from tensorflow.lite.python import util\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/lite/python/util.py\", line 53, in <module>\n",
      "    from jax import jit as _jit\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/jax/__init__.py\", line 39, in <module>\n",
      "    from jax import config as _config_module\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/jax/config.py\", line 15, in <module>\n",
      "    from jax._src.config import config as _deprecated_config  # noqa: F401\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/jax/_src/config.py\", line 28, in <module>\n",
      "    from jax._src import lib\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/jax/_src/lib/__init__.py\", line 90, in <module>\n",
      "    import jaxlib.xla_client as xla_client\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/jaxlib/xla_client.py\", line 29, in <module>\n",
      "    from . import xla_extension as _xla\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorboard/compat/__init__.py:42\u001b[39m, in \u001b[36mtf\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorboard\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m notf  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'notf' from 'tensorboard.compat' (/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorboard/compat/__init__.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: _ARRAY_API not found"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from tabulate import tabulate\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "# Trainer\n",
    "from src.trainer.trainer import Trainer\n",
    "\n",
    "# Models\n",
    "from src.models.mlp import MLP\n",
    "from src.models.p4_allcnn import P4AllCNNC\n",
    "from src.models.fA_p4_allcnn import fA_P4AllCNNC\n",
    "from src.models.p4m_allcnn import  P4MAllCNNC\n",
    "from src.models.fA_p4m_allcnn import fA_P4MAllCNNC\n",
    "from src.models.p4m_resnet import  P4MResNet\n",
    "from src.models.fA_p4_resnet import fA_P4MResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff987c1c-1bd1-43ff-9590-68b85acaaf0b",
   "metadata": {},
   "source": [
    "## CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e8db10c-d12b-45c5-929e-80f5d4d0ee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"../data\"\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "transform_test = transforms.ToTensor()\n",
    "\n",
    "full_train = datasets.CIFAR10(root=root_path, train=True, download=True, transform=transform_train)\n",
    "\n",
    "train_size = int(0.9 * len(full_train))\n",
    "val_size = len(full_train) - train_size\n",
    "train_set, val_set = random_split(full_train, [train_size, val_size])\n",
    "test_set = datasets.CIFAR10(root=root_path, train=False, download=True, transform=transform_test)\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a8241b-b5a8-479f-bb9e-29d536497c74",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ce515d9-ec4c-4468-a77b-067e2dc3389a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Helper Functions -----\n",
    "def init_model(name):\n",
    "    if name == \"p4_allcnn\":\n",
    "        return P4AllCNNC()\n",
    "    elif name == \"fA_p4_allcnn\":\n",
    "        return fA_P4AllCNNC()\n",
    "    elif name == \"p4m_allcnn\":\n",
    "        return P4MAllCNNC()\n",
    "    elif name == \"fA_p4m_allcnn\":\n",
    "        return fA_P4MAllCNNC()\n",
    "    elif name == \"p4m_resnet\":\n",
    "        return P4MResNet()\n",
    "    elif name == \"fA_p4_resnet\":\n",
    "        return fA_P4MResNet()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model name: {name}\")\n",
    "\n",
    "def init_optimizer(model, lr, weight_decay):\n",
    "    return optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "\n",
    "def init_scheduler(optimizer, milestones):\n",
    "    return optim.lr_scheduler.MultiStepLR(optimizer, milestones=[200, 250, 300], gamma=0.1)\n",
    "\n",
    "# ----- Helper Classes -----\n",
    "@dataclass\n",
    "class HyperParams:\n",
    "    lr: float\n",
    "    epochs: int\n",
    "    weight_decay: float\n",
    "    momentum: float\n",
    "    gamma: float\n",
    "    milestones: List[int] = field(default_factory=list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f09d087-4b4d-474a-ac17-1f4d87ae7cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Configuration -----\n",
    "num_iterations = 1\n",
    "log_dir = \"../logs\"\n",
    "\n",
    "model_hyperparameters = {\n",
    "    \"p4_allcnn\":  HyperParams(lr=0.01, epochs=3, weight_decay=1e-3, momentum=0.9, milestones=[200, 250, 300], gamma=0.1),\n",
    "    \"fA_p4_allcnn\": HyperParams(lr=0.01, epochs=3, weight_decay=1e-3, momentum=0.9, milestones=[200, 250, 300], gamma=0.1),\n",
    "    #\"p4m_allcnn\": HyperParams(lr=0.01, epochs=1, weight_decay=1e-3, momentum=0.9, milestones=[200, 250, 300], gamma=0.1),\n",
    "    #\"fA_p4m_allcnn\": HyperParams(lr=0.01, epochs=1, weight_decay=1e-3, momentum=0.9, milestones=[200, 250, 300], gamma=0.1),\n",
    "    \"p4m_resnet\": HyperParams(lr=0.05, epochs=3, weight_decay=0.0, momentum=0.9, milestones=[50, 100, 150], gamma=0.1),\n",
    "    # \"fA_p4_resnet\": HyperParams(lr=0.05, epochs=1, weight_decay=0.0, momentum=0.9, milestones=[50, 100, 150], gamma=0.1)\n",
    "}\n",
    "model_names = model_hyperparameters.keys()\n",
    "accuracies = {name: [] for name in model_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eec0884-5ebf-44a7-b0e7-dcf1f71216db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/1\n",
      "\n",
      "→ Training model: p4_allcnn\n",
      "Using device: cuda\n",
      "Current GPU: NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "Training model : p4_allcnn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|████████████████████████████████████████████████████████████████████| 3/3 [01:20<00:00, 26.68s/it, Train Acc=0.4667, Val Acc=0.3728, Train Loss=1.5844, Val Loss=1.8259]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Training model: fA_p4_allcnn\n",
      "Using device: cuda\n",
      "Current GPU: NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "Training model : fA_p4_allcnn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|████████████████████████████████████████████████████████████████████| 3/3 [02:44<00:00, 54.68s/it, Train Acc=0.4694, Val Acc=0.3432, Train Loss=1.5532, Val Loss=1.8732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Training model: p4m_resnet\n",
      "Using device: cuda\n",
      "Current GPU: NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "Training model : p4m_resnet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|████████████████████████████████████████████████████████████████████| 3/3 [04:03<00:00, 81.15s/it, Train Acc=0.6279, Val Acc=0.4970, Train Loss=1.0459, Val Loss=1.7660]\n"
     ]
    }
   ],
   "source": [
    "# ----- Main Training Loop -----\n",
    "for it in range(num_iterations):\n",
    "    print(f\"Iteration {it + 1}/{num_iterations}\")\n",
    "\n",
    "    for name in model_names:\n",
    "        print(f\"\\n→ Training model: {name}\")\n",
    "\n",
    "        # 1. Grab hyperparams for this model\n",
    "        hp = model_hyperparameters[name]\n",
    "\n",
    "        # 2. Initialize model, criterion, optimizer, scheduler\n",
    "        model = init_model(name)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(\n",
    "            model.parameters(),\n",
    "            lr=hp.lr,\n",
    "            momentum=hp.momentum,\n",
    "            weight_decay=hp.weight_decay\n",
    "        )\n",
    "        scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "            optimizer,\n",
    "            milestones=hp.milestones,\n",
    "            gamma=hp.gamma\n",
    "        )\n",
    "\n",
    "        # 3. Wrap in our Trainer (single‐model)\n",
    "        trainer = Trainer(\n",
    "            models={name: model},\n",
    "            optimizers=[optimizer],\n",
    "            criterions=[criterion],\n",
    "            schedulers=[scheduler],\n",
    "            log_dir=f\"{log_dir}/{name}\"\n",
    "        )\n",
    "\n",
    "        # 4. Train & validate with the model‐specific epoch count\n",
    "        trainer.train(\n",
    "            num_epochs=hp.epochs,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "        )\n",
    "\n",
    "        # 5. Evaluate on test set and record accuracy\n",
    "        test_acc = trainer.evaluate(test_loader=test_loader)[name]\n",
    "        accuracies[name].append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a805b45-7bdd-4bc9-84ca-581d7f5587f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Final Statistics -----\n",
    "final_stats = {\n",
    "    name: {\n",
    "        \"% Test error\": (1 - float(np.mean(vals))) * 100,\n",
    "        \"% std\": float(np.std(vals)) * 100,\n",
    "        \"Num Parameters\": sum(p.numel() for p in init_model(name).parameters())\n",
    "    }\n",
    "    for name, vals in accuracies.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2827a4-7a77-4f14-b1e4-f9eb7f10fd80",
   "metadata": {},
   "source": [
    "## Table generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dfa9492-1e4e-4e19-ad0f-7a384fa167f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Model Accuracy Summary in CIFAR10\n",
      "\n",
      "╒══════════════╤════════════════╤═════════╤══════════════════╕\n",
      "│              │   % Test error │   % std │   Num Parameters │\n",
      "╞══════════════╪════════════════╪═════════╪══════════════════╡\n",
      "│ p4_allcnn    │          64.38 │       0 │      1.37037e+06 │\n",
      "├──────────────┼────────────────┼─────────┼──────────────────┤\n",
      "│ fA_p4_allcnn │          65.76 │       0 │      1.40012e+06 │\n",
      "├──────────────┼────────────────┼─────────┼──────────────────┤\n",
      "│ p4m_resnet   │          50.89 │       0 │      2.62168e+06 │\n",
      "╘══════════════╧════════════════╧═════════╧══════════════════╛\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(final_stats, orient='index')\n",
    "df = df.round(2)\n",
    "print(\"📊 Model Accuracy Summary in CIFAR10\\n\")\n",
    "print(tabulate(df, headers=\"keys\", tablefmt=\"fancy_grid\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
