{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "035abcac-3d8c-4dd6-8722-a4e8abf2a1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Trainer\n",
    "from src.trainer.trainer import Trainer\n",
    "\n",
    "# Models\n",
    "from src.models.mlp import MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff987c1c-1bd1-43ff-9590-68b85acaaf0b",
   "metadata": {},
   "source": [
    "## CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e8db10c-d12b-45c5-929e-80f5d4d0ee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"../data\"\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "transform_test = transforms.ToTensor()\n",
    "\n",
    "full_train = datasets.CIFAR10(root=root_path, train=True, download=True, transform=transform_train)\n",
    "\n",
    "train_size = int(0.9 * len(full_train))\n",
    "val_size = len(full_train) - train_size\n",
    "train_set, val_set = random_split(full_train, [train_size, val_size])\n",
    "test_set = datasets.CIFAR10(root=root_path, train=False, download=True, transform=transform_test)\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bb54b7e-50ea-4216-8f2e-c80bad071194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "img, label = full_train[0]\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a8241b-b5a8-479f-bb9e-29d536497c74",
   "metadata": {},
   "source": [
    "## Table generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eec0884-5ebf-44a7-b0e7-dcf1f71216db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Current GPU: NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "Training models...\n",
      "Training model : mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.47s/it, Train Acc=0.2336, Val Acc=0.2454, Train Loss=2.0266, Val Loss=2.0364]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Current GPU: NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "Training models...\n",
      "Training model : mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.46s/it, Train Acc=0.2521, Val Acc=0.2730, Train Loss=1.9718, Val Loss=1.9753]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Current GPU: NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "Training models...\n",
      "Training model : mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:24<00:00,  2.46s/it, Train Acc=0.2191, Val Acc=0.2112, Train Loss=2.0283, Val Loss=2.0244]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Init training variables\n",
    "num_epochs = 10\n",
    "num_iterations = 3\n",
    "log_dir = \"../logs\"\n",
    "accuracies = {\n",
    "    \"mlp\": []\n",
    "}\n",
    "\n",
    "# ----- Init model paramerters -----\n",
    "\n",
    "## MLP parameters:\n",
    "input_size = 3 * 32 * 32\n",
    "output_size = 10\n",
    "hidden_sizes = [128, 64]\n",
    "\n",
    "## ---------------------------------\n",
    "\n",
    "for it in range(num_iterations):\n",
    "    \n",
    "    # ----- Models initialization -----\n",
    "    mlp_model = MLP(\n",
    "        input_size = input_size,\n",
    "        hidden_sizes = hidden_sizes,\n",
    "        output_size = output_size\n",
    "    )\n",
    "\n",
    "    # ---------------------------------\n",
    "\n",
    "    # ----- Other parameter initialization -----\n",
    "    mlp_criterion = nn.CrossEntropyLoss()\n",
    "    mlp_optimizer = optim.SGD(mlp_model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "    mlp_scheduler = optim.lr_scheduler.MultiStepLR(mlp_optimizer, milestones=[200, 250, 300], gamma=0.1)\n",
    "\n",
    "    # ------------------------------------------\n",
    "\n",
    "    # Generate lists\n",
    "    models = {\n",
    "        \"mlp\": mlp_model\n",
    "    }\n",
    "    criterions = [mlp_criterion]\n",
    "    optimizers = [mlp_optimizer]\n",
    "    schedulers = [mlp_scheduler]\n",
    "\n",
    "    # -------------------------------------------\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        models = models,\n",
    "        optimizers = optimizers,\n",
    "        criterions = criterions,\n",
    "        schedulers = schedulers,\n",
    "        log_dir = log_dir\n",
    "    )\n",
    "\n",
    "    # Train models on dataset\n",
    "    print(\"Training models...\")\n",
    "    trainer.train(\n",
    "        num_epochs = num_epochs,\n",
    "        train_loader = train_loader,\n",
    "        val_loader = val_loader,\n",
    "    )\n",
    "\n",
    "    # Evaluate models on dataset\n",
    "    print(\"Testing models...\")\n",
    "    test_accuracies = trainer.evaluate(test_loader = test_loader)\n",
    "\n",
    "    for model_name, acc in test_accuracies.items():\n",
    "        accuracies[model_name].append(acc)\n",
    "\n",
    "# get final statistics\n",
    "final_stats = {\n",
    "    model_name: {\n",
    "        \"% Test error\" : (1 - float(np.mean(values))) * 100,\n",
    "        \"% std\" : float(np.std(values)) * 100,\n",
    "        \"Num Parameters\" : sum(p.numel() for p in models[model_name].parameters()),\n",
    "    }\n",
    "    for model_name, values in accuracies.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2827a4-7a77-4f14-b1e4-f9eb7f10fd80",
   "metadata": {},
   "source": [
    "## Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dfa9492-1e4e-4e19-ad0f-7a384fa167f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Model Accuracy Summary in CIFAR10\n",
      "\n",
      "â•’â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
      "â”‚     â”‚   % Test error â”‚   % std â”‚   Num Parameters â”‚\n",
      "â•žâ•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ mlp â”‚          74.52 â”‚    2.38 â”‚           402250 â”‚\n",
      "â•˜â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(final_stats, orient='index')\n",
    "df = df.round(2)\n",
    "print(\"ðŸ“Š Model Accuracy Summary in CIFAR10\\n\")\n",
    "print(tabulate(df, headers=\"keys\", tablefmt=\"fancy_grid\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
