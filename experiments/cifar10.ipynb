{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "035abcac-3d8c-4dd6-8722-a4e8abf2a1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Trainer\n",
    "from src.trainer.trainer import Trainer\n",
    "\n",
    "# Models\n",
    "from src.models.mlp import MLP\n",
    "from src.models.p4_allcnn import P4AllCNNC\n",
    "from src.models.fA_p4_allcnn import fA_P4AllCNNC\n",
    "from src.models.p4m_allcnn import  P4MAllCNNC\n",
    "from src.models.fA_p4m_allcnn import fA_P4MAllCNNC\n",
    "from src.models.p4m_resnet import  P4MResNet\n",
    "from src.models.fA_p4_resnet import fA_P4MResNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff987c1c-1bd1-43ff-9590-68b85acaaf0b",
   "metadata": {},
   "source": [
    "## CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e8db10c-d12b-45c5-929e-80f5d4d0ee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"../data\"\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "transform_test = transforms.ToTensor()\n",
    "\n",
    "full_train = datasets.CIFAR10(root=root_path, train=True, download=True, transform=transform_train)\n",
    "\n",
    "train_size = int(0.9 * len(full_train))\n",
    "val_size = len(full_train) - train_size\n",
    "train_set, val_set = random_split(full_train, [train_size, val_size])\n",
    "test_set = datasets.CIFAR10(root=root_path, train=False, download=True, transform=transform_test)\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bb54b7e-50ea-4216-8f2e-c80bad071194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "img, label = full_train[0]\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a8241b-b5a8-479f-bb9e-29d536497c74",
   "metadata": {},
   "source": [
    "## Table generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3eec0884-5ebf-44a7-b0e7-dcf1f71216db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Training models...\n",
      "Training model : mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 0/3 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "Training Epochs:   0%|          | 0/3 [00:05<?, ?it/s]  File \"/Users/larabastos/miniconda3/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torchvision/__init__.py\", line 10, in <module>\n",
      "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils  # usort:skip\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torchvision/models/__init__.py\", line 2, in <module>\n",
      "    from .convnext import *\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torchvision/models/convnext.py\", line 8, in <module>\n",
      "    from ..ops.misc import Conv2dNormActivation, Permute\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torchvision/ops/__init__.py\", line 23, in <module>\n",
      "    from .poolers import MultiScaleRoIAlign\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torchvision/ops/poolers.py\", line 10, in <module>\n",
      "    from .roi_align import roi_align\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torchvision/ops/roi_align.py\", line 7, in <module>\n",
      "    from torch._dynamo.utils import is_compile_supported\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torch/_dynamo/__init__.py\", line 53, in <module>\n",
      "    from .polyfills import loader as _  # usort: skip # noqa: F401\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torch/_dynamo/polyfills/loader.py\", line 25, in <module>\n",
      "    POLYFILLED_MODULES: tuple[\"ModuleType\", ...] = tuple(\n",
      "                                                   ^^^^^^\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torch/_dynamo/polyfills/loader.py\", line 26, in <genexpr>\n",
      "    importlib.import_module(f\".{submodule}\", package=polyfills.__name__)\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torch/_dynamo/polyfills/builtins.py\", line 30, in <module>\n",
      "    @substitute_in_graph(builtins.all, can_constant_fold_through=True)\n",
      "     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torch/_dynamo/decorators.py\", line 427, in wrapper\n",
      "    rule_map: dict[Any, type[VariableTracker]] = get_torch_obj_rule_map()\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py\", line 2870, in get_torch_obj_rule_map\n",
      "    obj = load_object(k)\n",
      "          ^^^^^^^^^^^^^^\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py\", line 2901, in load_object\n",
      "    val = _load_obj_from_str(x[0])\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py\", line 2885, in _load_obj_from_str\n",
      "    return getattr(importlib.import_module(module), obj_name)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torch/_higher_order_ops/map.py\", line 6, in <module>\n",
      "    from torch._functorch.aot_autograd import AOTConfig, create_joint\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torch/_functorch/aot_autograd.py\", line 135, in <module>\n",
      "    from .partitioners import default_partition\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torch/_functorch/partitioners.py\", line 37, in <module>\n",
      "    from ._activation_checkpointing.graph_info_provider import GraphInfoProvider\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torch/_functorch/_activation_checkpointing/graph_info_provider.py\", line 3, in <module>\n",
      "    import networkx as nx\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/networkx/__init__.py\", line 39, in <module>\n",
      "    from networkx import generators\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/networkx/generators/__init__.py\", line 27, in <module>\n",
      "    from networkx.generators.small import *\n",
      "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1091, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1191, in get_data\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 135\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;66;03m# Train models on dataset\u001b[39;00m\n\u001b[32m    134\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining models...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[38;5;66;03m# Evaluate models on dataset\u001b[39;00m\n\u001b[32m    142\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTesting models...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/uni/msc/q4/frmdl/fundamental-research-project/experiments/../src/trainer/trainer.py:48\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, num_epochs, train_loader, val_loader)\u001b[39m\n\u001b[32m     45\u001b[39m model.to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m     46\u001b[39m total_loss, correct, total = \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:493\u001b[39m, in \u001b[36mDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    491\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:424\u001b[39m, in \u001b[36mDataLoader._get_iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    423\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_worker_number_rationality()\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1171\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter.__init__\u001b[39m\u001b[34m(self, loader)\u001b[39m\n\u001b[32m   1164\u001b[39m w.daemon = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1165\u001b[39m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[32m   1166\u001b[39m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[32m   1167\u001b[39m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[32m   1168\u001b[39m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[32m   1169\u001b[39m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[32m   1170\u001b[39m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1171\u001b[39m \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[38;5;28mself\u001b[39m._index_queues.append(index_queue)\n\u001b[32m   1173\u001b[39m \u001b[38;5;28mself\u001b[39m._workers.append(w)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/multiprocessing/process.py:121\u001b[39m, in \u001b[36mBaseProcess.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process._config.get(\u001b[33m'\u001b[39m\u001b[33mdaemon\u001b[39m\u001b[33m'\u001b[39m), \\\n\u001b[32m    119\u001b[39m        \u001b[33m'\u001b[39m\u001b[33mdaemonic processes are not allowed to have children\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    120\u001b[39m _cleanup()\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28mself\u001b[39m._popen = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mself\u001b[39m._sentinel = \u001b[38;5;28mself\u001b[39m._popen.sentinel\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/multiprocessing/context.py:224\u001b[39m, in \u001b[36mProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mProcess\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/multiprocessing/context.py:289\u001b[39m, in \u001b[36mSpawnProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    286\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m    288\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpopen_spawn_posix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/multiprocessing/popen_spawn_posix.py:32\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mself\u001b[39m._fds = []\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/multiprocessing/popen_fork.py:19\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mself\u001b[39m.returncode = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mself\u001b[39m.finalizer = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/multiprocessing/popen_spawn_posix.py:62\u001b[39m, in \u001b[36mPopen._launch\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.sentinel = parent_r\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m, closefd=\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m         \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetbuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     64\u001b[39m     fds_to_close = []\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Init training variables\n",
    "num_epochs = 3 #10\n",
    "num_iterations = 1#3\n",
    "log_dir = \"../logs\"\n",
    "accuracies = {\n",
    "    \"mlp\": [],\n",
    "    \"p4_allcnn\": [],\n",
    "    \"fA_p4_allcnn\": [],\n",
    "    \"p4m_allcnn\": [],\n",
    "    \"fA_p4m_allcnn\": [],\n",
    "    \"p4m_resnet\": [],\n",
    "    \"fA_p4_resnet\": []\n",
    "}\n",
    "\n",
    "# ----- Init model paramerters -----\n",
    "\n",
    "## MLP parameters:\n",
    "input_size = 3 * 32 * 32\n",
    "output_size = 10\n",
    "hidden_sizes = [128, 64]\n",
    "\n",
    "## ---------------------------------\n",
    "\n",
    "for it in range(num_iterations):\n",
    "\n",
    "    # ----- Models initialization -----\n",
    "    mlp_model = MLP(\n",
    "        input_size = input_size,\n",
    "        hidden_sizes = hidden_sizes,\n",
    "        output_size = output_size\n",
    "    )\n",
    "\n",
    "    p4_allcnn_model = P4AllCNNC()\n",
    "    fA_p4_allcnn_model= fA_P4AllCNNC()\n",
    "    p4m_allcnn_model = P4MAllCNNC()\n",
    "    fA_p4m_allcnn_model = fA_P4MAllCNNC()\n",
    "\n",
    "    p4m_resnet_model = P4MResNet()\n",
    "    fA_p4_resnet_model= fA_P4MResNet()\n",
    "\n",
    "\n",
    "    # ---------------------------------\n",
    "\n",
    "    # ----- Other parameter initialization -----\n",
    "    mlp_criterion = nn.CrossEntropyLoss()\n",
    "    mlp_optimizer = optim.SGD(mlp_model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "    mlp_scheduler = optim.lr_scheduler.MultiStepLR(mlp_optimizer, milestones=[200, 250, 300], gamma=0.1)\n",
    "\n",
    "    # P4AllCNNC\n",
    "    p4_allcnn_criterion = nn.CrossEntropyLoss()\n",
    "    p4_allcnn_optimizer = optim.SGD(p4_allcnn_model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "    p4_allcnn_scheduler = optim.lr_scheduler.MultiStepLR(p4_allcnn_optimizer, milestones=[200, 250, 300], gamma=0.1)\n",
    "\n",
    "    # fA_P4AllCNNC\n",
    "    fA_p4_allcnn_criterion = nn.CrossEntropyLoss()\n",
    "    fA_p4_allcnn_optimizer = optim.SGD(fA_p4_allcnn_model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "    fA_p4_allcnn_scheduler = optim.lr_scheduler.MultiStepLR(fA_p4_allcnn_optimizer, milestones=[200, 250, 300], gamma=0.1)\n",
    "\n",
    "    # P4MAllCNNC\n",
    "    p4m_allcnn_criterion = nn.CrossEntropyLoss()\n",
    "    p4m_allcnn_optimizer = optim.SGD(p4m_allcnn_model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "    p4m_allcnn_scheduler = optim.lr_scheduler.MultiStepLR(p4m_allcnn_optimizer, milestones=[200, 250, 300], gamma=0.1)\n",
    "\n",
    "    # fA_P4MAllCNNC\n",
    "    fA_p4m_allcnn_criterion = nn.CrossEntropyLoss()\n",
    "    fA_p4m_allcnn_optimizer = optim.SGD(fA_p4m_allcnn_model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "    fA_p4m_allcnn_scheduler = optim.lr_scheduler.MultiStepLR(fA_p4m_allcnn_optimizer, milestones=[200, 250, 300], gamma=0.1)\n",
    "\n",
    "    # P4MResNet\n",
    "    p4m_resnet_criterion = nn.CrossEntropyLoss()\n",
    "    p4m_resnet_optimizer = optim.SGD(p4m_resnet_model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "    p4m_resnet_scheduler = optim.lr_scheduler.MultiStepLR(p4m_resnet_optimizer, milestones=[200, 250, 300], gamma=0.1)\n",
    "\n",
    "    # fA_P4MResNet\n",
    "    fA_p4_resnet_criterion = nn.CrossEntropyLoss()\n",
    "    fA_p4_resnet_optimizer = optim.SGD(fA_p4_resnet_model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "    fA_p4_resnet_scheduler = optim.lr_scheduler.MultiStepLR(fA_p4_resnet_optimizer, milestones=[200, 250, 300], gamma=0.1)\n",
    "\n",
    "\n",
    "    # ------------------------------------------\n",
    "\n",
    "    # Generate lists\n",
    "    models = {\n",
    "    \"mlp\": mlp_model,\n",
    "    \"p4_allcnn\": p4_allcnn_model,\n",
    "    \"fA_p4_allcnn\": fA_p4_allcnn_model,\n",
    "    \"p4m_allcnn\": p4m_allcnn_model,\n",
    "    \"fA_p4m_allcnn\": fA_p4m_allcnn_model,\n",
    "    \"p4m_resnet\": p4m_resnet_model,\n",
    "    \"fA_p4_resnet\": fA_p4_resnet_model\n",
    "    }\n",
    "\n",
    "    criterions = [\n",
    "        mlp_criterion,\n",
    "        p4_allcnn_criterion,\n",
    "        fA_p4_allcnn_criterion,\n",
    "        p4m_allcnn_criterion,\n",
    "        fA_p4m_allcnn_criterion,\n",
    "        p4m_resnet_criterion,\n",
    "        fA_p4_resnet_criterion\n",
    "    ]\n",
    "\n",
    "    optimizers = [\n",
    "        mlp_optimizer,\n",
    "        p4_allcnn_optimizer,\n",
    "        fA_p4_allcnn_optimizer,\n",
    "        p4m_allcnn_optimizer,\n",
    "        fA_p4m_allcnn_optimizer,\n",
    "        p4m_resnet_optimizer,\n",
    "        fA_p4_resnet_optimizer\n",
    "    ]\n",
    "\n",
    "    schedulers = [\n",
    "        mlp_scheduler,\n",
    "        p4_allcnn_scheduler,\n",
    "        fA_p4_allcnn_scheduler,\n",
    "        p4m_allcnn_scheduler,\n",
    "        fA_p4m_allcnn_scheduler,\n",
    "        p4m_resnet_scheduler,\n",
    "        fA_p4_resnet_scheduler\n",
    "    ]\n",
    "\n",
    "    # -------------------------------------------\n",
    "\n",
    "    trainer = Trainer(\n",
    "        models = models,\n",
    "        optimizers = optimizers,\n",
    "        criterions = criterions,\n",
    "        schedulers = schedulers,\n",
    "        log_dir = log_dir\n",
    "    )\n",
    "\n",
    "    # Train models on dataset\n",
    "    print(\"Training models...\")\n",
    "    trainer.train(\n",
    "        num_epochs = num_epochs,\n",
    "        train_loader = train_loader,\n",
    "        val_loader = val_loader,\n",
    "    )\n",
    "\n",
    "    # Evaluate models on dataset\n",
    "    print(\"Testing models...\")\n",
    "    test_accuracies = trainer.evaluate(test_loader = test_loader)\n",
    "\n",
    "    for model_name, acc in test_accuracies.items():\n",
    "        accuracies[model_name].append(acc)\n",
    "\n",
    "# get final statistics\n",
    "final_stats = {\n",
    "    model_name: {\n",
    "        \"% Test error\" : (1 - float(np.mean(values))) * 100,\n",
    "        \"% std\" : float(np.std(values)) * 100,\n",
    "        \"Num Parameters\" : sum(p.numel() for p in models[model_name].parameters()),\n",
    "    }\n",
    "    for model_name, values in accuracies.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2827a4-7a77-4f14-b1e4-f9eb7f10fd80",
   "metadata": {},
   "source": [
    "## Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dfa9492-1e4e-4e19-ad0f-7a384fa167f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Model Accuracy Summary in CIFAR10\n",
      "\n",
      "╒═════╤════════════════╤═════════╤══════════════════╕\n",
      "│     │   % Test error │   % std │   Num Parameters │\n",
      "╞═════╪════════════════╪═════════╪══════════════════╡\n",
      "│ mlp │          74.52 │    2.38 │           402250 │\n",
      "╘═════╧════════════════╧═════════╧══════════════════╛\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(final_stats, orient='index')\n",
    "df = df.round(2)\n",
    "print(\"📊 Model Accuracy Summary in CIFAR10\\n\")\n",
    "print(tabulate(df, headers=\"keys\", tablefmt=\"fancy_grid\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
