{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "035abcac-3d8c-4dd6-8722-a4e8abf2a1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.5 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3047, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3102, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3489, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3549, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/40/y2m0v2h9587d4pnsspl6bs6c0000gn/T/ipykernel_5456/2987838745.py\", line 17, in <module>\n",
      "    from src.trainer.trainer import Trainer\n",
      "  File \"/Users/larabastos/Desktop/uni/msc/q4/frmdl/fundamental-research-project/experiments/../src/trainer/trainer.py\", line 2, in <module>\n",
      "    from torch.utils.tensorboard import SummaryWriter\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torch/utils/tensorboard/__init__.py\", line 12, in <module>\n",
      "    from .writer import FileWriter, SummaryWriter\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torch/utils/tensorboard/writer.py\", line 19, in <module>\n",
      "    from ._embedding import get_embedding_info, make_mat, make_sprite, make_tsv, write_pbtxt\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torch/utils/tensorboard/_embedding.py\", line 10, in <module>\n",
      "    _HAS_GFILE_JOIN = hasattr(tf.io.gfile, \"join\")\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorboard/lazy.py\", line 65, in __getattr__\n",
      "    return getattr(load_once(self), attr_name)\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorboard/lazy.py\", line 97, in wrapper\n",
      "    cache[arg] = f(arg)\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorboard/lazy.py\", line 50, in load_once\n",
      "    module = load_fn()\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorboard/compat/__init__.py\", line 45, in tf\n",
      "    import tensorflow\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/__init__.py\", line 55, in <module>\n",
      "    from tensorflow._api.v2 import compat\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/_api/v2/compat/__init__.py\", line 8, in <module>\n",
      "    from tensorflow._api.v2.compat import v1\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/_api/v2/compat/v1/__init__.py\", line 30, in <module>\n",
      "    from tensorflow._api.v2.compat.v1 import compat\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py\", line 8, in <module>\n",
      "    from tensorflow._api.v2.compat.v1.compat import v1\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/_api/v2/compat/v1/compat/v1/__init__.py\", line 47, in <module>\n",
      "    from tensorflow._api.v2.compat.v1 import lite\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/_api/v2/compat/v1/lite/__init__.py\", line 9, in <module>\n",
      "    from tensorflow._api.v2.compat.v1.lite import experimental\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/_api/v2/compat/v1/lite/experimental/__init__.py\", line 8, in <module>\n",
      "    from tensorflow._api.v2.compat.v1.lite.experimental import authoring\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/_api/v2/compat/v1/lite/experimental/authoring/__init__.py\", line 8, in <module>\n",
      "    from tensorflow.lite.python.authoring.authoring import compatible # line: 263\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/lite/python/authoring/authoring.py\", line 42, in <module>\n",
      "    from tensorflow.lite.python import convert\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/lite/python/convert.py\", line 31, in <module>\n",
      "    from tensorflow.lite.python import util\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/lite/python/util.py\", line 53, in <module>\n",
      "    from jax import jit as _jit\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/jax/__init__.py\", line 39, in <module>\n",
      "    from jax import config as _config_module\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/jax/config.py\", line 15, in <module>\n",
      "    from jax._src.config import config as _deprecated_config  # noqa: F401\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/jax/_src/config.py\", line 28, in <module>\n",
      "    from jax._src import lib\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/jax/_src/lib/__init__.py\", line 90, in <module>\n",
      "    import jaxlib.xla_client as xla_client\n",
      "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/jaxlib/xla_client.py\", line 29, in <module>\n",
      "    from . import xla_extension as _xla\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorboard/compat/__init__.py:42\u001b[39m, in \u001b[36mtf\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorboard\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m notf  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'notf' from 'tensorboard.compat' (/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorboard/compat/__init__.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: _ARRAY_API not found"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from tabulate import tabulate\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "# Trainer\n",
    "from src.trainer.trainer import Trainer\n",
    "\n",
    "# Models\n",
    "from src.models.mlp import MLP\n",
    "from src.models.p4_allcnn import P4AllCNNC\n",
    "from src.models.fA_p4_allcnn import fA_P4AllCNNC\n",
    "from src.models.p4m_allcnn import  P4MAllCNNC\n",
    "from src.models.fA_p4m_allcnn import fA_P4MAllCNNC\n",
    "from src.models.p4m_resnet import  P4MResNet\n",
    "from src.models.fA_p4_resnet import fA_P4MResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff987c1c-1bd1-43ff-9590-68b85acaaf0b",
   "metadata": {},
   "source": [
    "## CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e8db10c-d12b-45c5-929e-80f5d4d0ee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"../data\"\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "transform_test = transforms.ToTensor()\n",
    "\n",
    "full_train = datasets.CIFAR10(root=root_path, train=True, download=True, transform=transform_train)\n",
    "\n",
    "train_size = int(0.9 * len(full_train))\n",
    "val_size = len(full_train) - train_size\n",
    "train_set, val_set = random_split(full_train, [train_size, val_size])\n",
    "test_set = datasets.CIFAR10(root=root_path, train=False, download=True, transform=transform_test)\n",
    "\n",
    "num_workers = 4\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a8241b-b5a8-479f-bb9e-29d536497c74",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ce515d9-ec4c-4468-a77b-067e2dc3389a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Helper Functions -----\n",
    "def init_model(name):\n",
    "    if name == \"p4_allcnn\":\n",
    "        return P4AllCNNC()\n",
    "    elif name == \"fA_p4_allcnn\":\n",
    "        return fA_P4AllCNNC()\n",
    "    elif name == \"p4m_allcnn\":\n",
    "        return P4MAllCNNC()\n",
    "    elif name == \"fA_p4m_allcnn\":\n",
    "        return fA_P4MAllCNNC()\n",
    "    elif name == \"p4m_resnet\":\n",
    "        return P4MResNet()\n",
    "    elif name == \"fA_p4_resnet\":\n",
    "        return fA_P4MResNet()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model name: {name}\")\n",
    "\n",
    "def init_optimizer(model, lr, weight_decay):\n",
    "    return optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "\n",
    "def init_scheduler(optimizer, milestones):\n",
    "    return optim.lr_scheduler.MultiStepLR(optimizer, milestones=[200, 250, 300], gamma=0.1)\n",
    "\n",
    "# ----- Helper Classes -----\n",
    "@dataclass\n",
    "class HyperParams:\n",
    "    lr: float\n",
    "    epochs: int\n",
    "    weight_decay: float\n",
    "    momentum: float\n",
    "    gamma: float\n",
    "    milestones: List[int] = field(default_factory=list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f09d087-4b4d-474a-ac17-1f4d87ae7cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Configuration -----\n",
    "num_iterations = 1\n",
    "log_dir = \"../logs\"\n",
    "\n",
    "model_hyperparameters = {\n",
    "    \"p4_allcnn\":  HyperParams(lr=0.01, epochs=3, weight_decay=1e-3, momentum=0.9, milestones=[200, 250, 300], gamma=0.1),\n",
    "    \"fA_p4_allcnn\": HyperParams(lr=0.01, epochs=3, weight_decay=1e-3, momentum=0.9, milestones=[200, 250, 300], gamma=0.1),\n",
    "    #\"p4m_allcnn\": HyperParams(lr=0.01, epochs=1, weight_decay=1e-3, momentum=0.9, milestones=[200, 250, 300], gamma=0.1),\n",
    "    #\"fA_p4m_allcnn\": HyperParams(lr=0.01, epochs=1, weight_decay=1e-3, momentum=0.9, milestones=[200, 250, 300], gamma=0.1),\n",
    "    \"p4m_resnet\": HyperParams(lr=0.05, epochs=3, weight_decay=0.0, momentum=0.9, milestones=[50, 100, 150], gamma=0.1),\n",
    "    # \"fA_p4_resnet\": HyperParams(lr=0.05, epochs=1, weight_decay=0.0, momentum=0.9, milestones=[50, 100, 150], gamma=0.1)\n",
    "}\n",
    "model_names = model_hyperparameters.keys()\n",
    "accuracies = {name: [] for name in model_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eec0884-5ebf-44a7-b0e7-dcf1f71216db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/1\n",
      "\n",
      "‚Üí Training model: p4_allcnn\n",
      "Using device: cuda\n",
      "Current GPU: NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "Training model : p4_allcnn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [

      "Training Epochs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [01:22<00:00, 27.61s/it, Train Acc=0.4755, Val Acc=0.3588, Train Loss=1.5618, Val Loss=1.8214]\n"

     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚Üí Training model: fA_p4_allcnn\n",
      "Using device: cuda\n",
      "Current GPU: NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "Training model : fA_p4_allcnn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                                                                                                  | 0/3 [00:18<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 36\u001b[0m\n\u001b[1;32m     27\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     28\u001b[0m     models\u001b[38;5;241m=\u001b[39m{name: model},\n\u001b[1;32m     29\u001b[0m     optimizers\u001b[38;5;241m=\u001b[39m[optimizer],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     log_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlog_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# 4. Train & validate with the model‚Äêspecific epoch count\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# 5. Evaluate on test set and record accuracy\u001b[39;00m\n\u001b[1;32m     43\u001b[0m test_acc \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate(test_loader\u001b[38;5;241m=\u001b[39mtest_loader)[name]\n",
      "File \u001b[0;32m~/Desktop/TUDelft/Master/Q4 - Fundamental Research in Machine and Deep Learning/Project/fundamental-research-project/experiments/../src/trainer/trainer.py:65\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, num_epochs, train_loader, val_loader)\u001b[0m\n\u001b[1;32m     63\u001b[0m scaler\u001b[38;5;241m.\u001b[39munscale_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizers[i])\n\u001b[1;32m     64\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m     67\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/TUDelft/Master/Q4 - Fundamental Research in Machine and Deep Learning/Project/fundamental-research-project/.venv/lib/python3.12/site-packages/torch/amp/grad_scaler.py:457\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    455\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 457\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/Desktop/TUDelft/Master/Q4 - Fundamental Research in Machine and Deep Learning/Project/fundamental-research-project/.venv/lib/python3.12/site-packages/torch/amp/grad_scaler.py:351\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf_per_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/Desktop/TUDelft/Master/Q4 - Fundamental Research in Machine and Deep Learning/Project/fundamental-research-project/.venv/lib/python3.12/site-packages/torch/amp/grad_scaler.py:351\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ----- Main Training Loop -----\n",
    "for it in range(num_iterations):\n",
    "    print(f\"Iteration {it + 1}/{num_iterations}\")\n",
    "\n",
    "    for name in model_names:\n",
    "        print(f\"\\n‚Üí Training model: {name}\")\n",
    "\n",
    "        # 1. Grab hyperparams for this model\n",
    "        hp = model_hyperparameters[name]\n",
    "\n",
    "        # 2. Initialize model, criterion, optimizer, scheduler\n",
    "        model = init_model(name)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(\n",
    "            model.parameters(),\n",
    "            lr=hp.lr,\n",
    "            momentum=hp.momentum,\n",
    "            weight_decay=hp.weight_decay\n",
    "        )\n",
    "        scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "            optimizer,\n",
    "            milestones=hp.milestones,\n",
    "            gamma=hp.gamma\n",
    "        )\n",
    "\n",
    "        # 3. Wrap in our Trainer (single‚Äêmodel)\n",
    "        trainer = Trainer(\n",
    "            models={name: model},\n",
    "            optimizers=[optimizer],\n",
    "            criterions=[criterion],\n",
    "            schedulers=[scheduler],\n",
    "            log_dir=f\"{log_dir}/{name}\"\n",
    "        )\n",
    "\n",
    "        # 4. Train & validate with the model‚Äêspecific epoch count\n",
    "        trainer.train(\n",
    "            num_epochs=hp.epochs,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "        )\n",
    "\n",
    "        # 5. Evaluate on test set and record accuracy\n",
    "        test_acc = trainer.evaluate(test_loader=test_loader)[name]\n",
    "        accuracies[name].append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a805b45-7bdd-4bc9-84ca-581d7f5587f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Final Statistics -----\n",
    "final_stats = {\n",
    "    name: {\n",
    "        \"% Test error\": (1 - float(np.mean(vals))) * 100,\n",
    "        \"% std\": float(np.std(vals)) * 100,\n",
    "        \"Num Parameters\": sum(p.numel() for p in init_model(name).parameters())\n",
    "    }\n",
    "    for name, vals in accuracies.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2827a4-7a77-4f14-b1e4-f9eb7f10fd80",
   "metadata": {},
   "source": [
    "## Table generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfa9492-1e4e-4e19-ad0f-7a384fa167f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(final_stats, orient='index')\n",
    "df = df.round(2)\n",
    "print(\"üìä Model Accuracy Summary in CIFAR10\\n\")\n",
    "print(tabulate(df, headers=\"keys\", tablefmt=\"fancy_grid\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
