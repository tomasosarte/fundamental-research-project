{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "035abcac-3d8c-4dd6-8722-a4e8abf2a1fe",
      "metadata": {
        "id": "035abcac-3d8c-4dd6-8722-a4e8abf2a1fe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.5 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
            "    app.start()\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n",
            "    handle._run()\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
            "    await result\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
            "    await super().execute_request(stream, ident, parent)\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3047, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3102, in _run_cell\n",
            "    result = runner(coro)\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3489, in run_ast_nodes\n",
            "    if await self.run_code(code, result, async_=asy):\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3549, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/var/folders/40/y2m0v2h9587d4pnsspl6bs6c0000gn/T/ipykernel_21503/2043813380.py\", line 18, in <module>\n",
            "    from src.trainer.trainer import Trainer\n",
            "  File \"/Users/larabastos/Desktop/uni/msc/q4/frmdl/fundamental-research-project/experiments/../src/trainer/trainer.py\", line 2, in <module>\n",
            "    from torch.utils.tensorboard import SummaryWriter\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torch/utils/tensorboard/__init__.py\", line 12, in <module>\n",
            "    from .writer import FileWriter, SummaryWriter\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torch/utils/tensorboard/writer.py\", line 19, in <module>\n",
            "    from ._embedding import get_embedding_info, make_mat, make_sprite, make_tsv, write_pbtxt\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torch/utils/tensorboard/_embedding.py\", line 10, in <module>\n",
            "    _HAS_GFILE_JOIN = hasattr(tf.io.gfile, \"join\")\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorboard/lazy.py\", line 65, in __getattr__\n",
            "    return getattr(load_once(self), attr_name)\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorboard/lazy.py\", line 97, in wrapper\n",
            "    cache[arg] = f(arg)\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorboard/lazy.py\", line 50, in load_once\n",
            "    module = load_fn()\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorboard/compat/__init__.py\", line 45, in tf\n",
            "    import tensorflow\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/__init__.py\", line 55, in <module>\n",
            "    from tensorflow._api.v2 import compat\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/_api/v2/compat/__init__.py\", line 8, in <module>\n",
            "    from tensorflow._api.v2.compat import v1\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/_api/v2/compat/v1/__init__.py\", line 30, in <module>\n",
            "    from tensorflow._api.v2.compat.v1 import compat\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py\", line 8, in <module>\n",
            "    from tensorflow._api.v2.compat.v1.compat import v1\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/_api/v2/compat/v1/compat/v1/__init__.py\", line 47, in <module>\n",
            "    from tensorflow._api.v2.compat.v1 import lite\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/_api/v2/compat/v1/lite/__init__.py\", line 9, in <module>\n",
            "    from tensorflow._api.v2.compat.v1.lite import experimental\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/_api/v2/compat/v1/lite/experimental/__init__.py\", line 8, in <module>\n",
            "    from tensorflow._api.v2.compat.v1.lite.experimental import authoring\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/_api/v2/compat/v1/lite/experimental/authoring/__init__.py\", line 8, in <module>\n",
            "    from tensorflow.lite.python.authoring.authoring import compatible # line: 263\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/lite/python/authoring/authoring.py\", line 42, in <module>\n",
            "    from tensorflow.lite.python import convert\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/lite/python/convert.py\", line 31, in <module>\n",
            "    from tensorflow.lite.python import util\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/lite/python/util.py\", line 53, in <module>\n",
            "    from jax import jit as _jit\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/jax/__init__.py\", line 39, in <module>\n",
            "    from jax import config as _config_module\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/jax/config.py\", line 15, in <module>\n",
            "    from jax._src.config import config as _deprecated_config  # noqa: F401\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/jax/_src/config.py\", line 28, in <module>\n",
            "    from jax._src import lib\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/jax/_src/lib/__init__.py\", line 90, in <module>\n",
            "    import jaxlib.xla_client as xla_client\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/jaxlib/xla_client.py\", line 29, in <module>\n",
            "    from . import xla_extension as _xla\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "_ARRAY_API not found",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorboard/compat/__init__.py:42\u001b[39m, in \u001b[36mtf\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorboard\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m notf  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
            "\u001b[31mImportError\u001b[39m: cannot import name 'notf' from 'tensorboard.compat' (/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorboard/compat/__init__.py)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[31mAttributeError\u001b[39m: _ARRAY_API not found"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import List\n",
        "from tabulate import tabulate\n",
        "from dataclasses import dataclass, field\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Trainer\n",
        "from src.trainer.trainer import Trainer\n",
        "\n",
        "# Models\n",
        "from src.models.chA_p4_cnn import A_Ch_P4CNN\n",
        "from src.models.spA_p4_cnn import A_Sp_P4CNN\n",
        "from src.models.fA_p4_allcnn import fA_P4AllCNNC\n",
        "from src.models.big_cnn import B15_P4CNN, B11_P4CNN\n",
        "\n",
        "# Data Utils\n",
        "from src.datasets.rot_mnist_dataset import get_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff987c1c-1bd1-43ff-9590-68b85acaaf0b",
      "metadata": {
        "id": "ff987c1c-1bd1-43ff-9590-68b85acaaf0b"
      },
      "source": [
        "## rot-MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0e8db10c-d12b-45c5-929e-80f5d4d0ee56",
      "metadata": {
        "id": "0e8db10c-d12b-45c5-929e-80f5d4d0ee56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading rotated MNIST dataset...\n",
            "Extracting contents...\n",
            "Converting .amat files to .npz...\n",
            "Done. Saved to: ../data\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_loader, val_loader, test_loader = get_dataset(batch_size=128, num_workers=2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3bb54b7e-50ea-4216-8f2e-c80bad071194",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "3bb54b7e-50ea-4216-8f2e-c80bad071194",
        "outputId": "32c6ac76-2f6f-49f3-843f-7f65eba1d6ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image shape: torch.Size([1, 28, 28])\n",
            "Squeezed shape: (28, 28)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "images, labels = next(iter(train_loader))\n",
        "\n",
        "print(\"Image shape:\", images[0].shape)  \n",
        "image = images[0].squeeze().cpu().numpy()  \n",
        "print(\"Squeezed shape:\", image.shape)  \n",
        "\n",
        "# Plot\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.title(f\"Label: {labels[0].item()}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6a8241b-b5a8-479f-bb9e-29d536497c74",
      "metadata": {
        "id": "f6a8241b-b5a8-479f-bb9e-29d536497c74"
      },
      "source": [
        "## Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4ce515d9-ec4c-4468-a77b-067e2dc3389a",
      "metadata": {
        "id": "4ce515d9-ec4c-4468-a77b-067e2dc3389a"
      },
      "outputs": [],
      "source": [
        "# ----- Helper Functions -----\n",
        "def init_model(name):\n",
        "    if name == \"big15_p4_cnn\":\n",
        "        return B15_P4CNN()\n",
        "    if name == \"chA_p4_cnn\":\n",
        "        return A_Ch_P4CNN()\n",
        "    elif name == \"spA_p4_cnn\":\n",
        "        return A_Sp_P4CNN()\n",
        "    elif name == \"big11_p4_cnn\":\n",
        "        return B11_P4CNN()\n",
        "    elif name == \"fA_p4_allcnn\":\n",
        "        return fA_P4AllCNNC()\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model name: {name}\")\n",
        "\n",
        "def init_optimizer(model, lr, weight_decay):\n",
        "    return optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
        "\n",
        "def init_scheduler(optimizer, milestones):\n",
        "    return optim.lr_scheduler.MultiStepLR(optimizer, milestones=[200, 250, 300], gamma=0.1)\n",
        "\n",
        "# ----- Helper Classes -----\n",
        "@dataclass\n",
        "class HyperParams:\n",
        "    lr: float\n",
        "    epochs: int\n",
        "    weight_decay: float\n",
        "    momentum: float\n",
        "    gamma: float\n",
        "    milestones: List[int] = field(default_factory=list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "9f09d087-4b4d-474a-ac17-1f4d87ae7cb4",
      "metadata": {
        "id": "9f09d087-4b4d-474a-ac17-1f4d87ae7cb4"
      },
      "outputs": [],
      "source": [
        "# ----- Configuration -----\n",
        "num_iterations = 3\n",
        "log_dir = \"../logs\"\n",
        "\n",
        "model_hyperparameters = {\n",
        "    \"big15_p4_cnn\":  HyperParams(lr=0.01, epochs=10, weight_decay=1e-3, momentum=0.9, milestones=[200, 250, 300], gamma=0.1),\n",
        "    \"chA_p4_cnn\":  HyperParams(lr=0.01, epochs=10, weight_decay=1e-3, momentum=0.9, milestones=[200, 250, 300], gamma=0.1),\n",
        "    \"spA_p4_cnn\": HyperParams(lr=0.01, epochs=10, weight_decay=1e-3, momentum=0.9, milestones=[200, 250, 300], gamma=0.1),\n",
        "    \"big11_p4_cnn\":  HyperParams(lr=0.01, epochs=10, weight_decay=1e-3, momentum=0.9, milestones=[200, 250, 300], gamma=0.1),\n",
        "    \"fA_p4_allcnn\": HyperParams(lr=0.01, epochs=10, weight_decay=1e-3, momentum=0.9, milestones=[200, 250, 300], gamma=0.1)\n",
        "}\n",
        "model_names = model_hyperparameters.keys()\n",
        "accuracies = {name: [] for name in model_names}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3eec0884-5ebf-44a7-b0e7-dcf1f71216db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eec0884-5ebf-44a7-b0e7-dcf1f71216db",
        "outputId": "24b6f1f2-4414-4705-a351-6f00636ec8fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1/3\n",
            "\n",
            "â†’ Training model: big15_p4_cnn\n",
            "Using device: cuda\n",
            "Current GPU: Tesla T4\n",
            "Training model : big15_p4_cnn\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:26<00:00,  2.69s/it, Train Acc=0.7866, Val Acc=0.7558, Train Loss=0.6438, Val Loss=0.7592]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "â†’ Training model: chA_p4_cnn\n",
            "Using device: cuda\n",
            "Current GPU: Tesla T4\n",
            "Training model : chA_p4_cnn\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:33<00:00,  9.31s/it, Train Acc=0.9231, Val Acc=0.9550, Train Loss=0.2415, Val Loss=0.1443]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "â†’ Training model: spA_p4_cnn\n",
            "Using device: cuda\n",
            "Current GPU: Tesla T4\n",
            "Training model : spA_p4_cnn\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:12<00:00, 13.22s/it, Train Acc=0.9331, Val Acc=0.9475, Train Loss=0.2117, Val Loss=0.1689]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "â†’ Training model: big11_p4_cnn\n",
            "Using device: cuda\n",
            "Current GPU: Tesla T4\n",
            "Training model : big11_p4_cnn\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:17<00:00,  1.77s/it, Train Acc=0.9201, Val Acc=0.9492, Train Loss=0.2512, Val Loss=0.1607]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "â†’ Training model: fA_p4_allcnn\n",
            "Using device: cuda\n",
            "Current GPU: Tesla T4\n",
            "Training model : fA_p4_allcnn\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:01<00:00, 12.16s/it, Train Acc=0.9625, Val Acc=0.9283, Train Loss=0.2245, Val Loss=0.3012]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 2/3\n",
            "\n",
            "â†’ Training model: big15_p4_cnn\n",
            "Using device: cuda\n",
            "Current GPU: Tesla T4\n",
            "Training model : big15_p4_cnn\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.52s/it, Train Acc=0.7370, Val Acc=0.3667, Train Loss=0.8096, Val Loss=2.4863]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "â†’ Training model: chA_p4_cnn\n",
            "Using device: cuda\n",
            "Current GPU: Tesla T4\n",
            "Training model : chA_p4_cnn\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:32<00:00,  9.23s/it, Train Acc=0.9292, Val Acc=0.9617, Train Loss=0.2340, Val Loss=0.1233]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "â†’ Training model: spA_p4_cnn\n",
            "Using device: cuda\n",
            "Current GPU: Tesla T4\n",
            "Training model : spA_p4_cnn\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:11<00:00, 13.13s/it, Train Acc=0.9323, Val Acc=0.9533, Train Loss=0.2153, Val Loss=0.1458]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "â†’ Training model: big11_p4_cnn\n",
            "Using device: cuda\n",
            "Current GPU: Tesla T4\n",
            "Training model : big11_p4_cnn\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:17<00:00,  1.78s/it, Train Acc=0.9244, Val Acc=0.9575, Train Loss=0.2403, Val Loss=0.1539]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "â†’ Training model: fA_p4_allcnn\n",
            "Using device: cuda\n",
            "Current GPU: Tesla T4\n",
            "Training model : fA_p4_allcnn\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:02<00:00, 12.22s/it, Train Acc=0.9652, Val Acc=0.9583, Train Loss=0.2108, Val Loss=0.2096]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 3/3\n",
            "\n",
            "â†’ Training model: big15_p4_cnn\n",
            "Using device: cuda\n",
            "Current GPU: Tesla T4\n",
            "Training model : big15_p4_cnn\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:25<00:00,  2.55s/it, Train Acc=0.7190, Val Acc=0.4983, Train Loss=0.8299, Val Loss=1.6708]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "â†’ Training model: chA_p4_cnn\n",
            "Using device: cuda\n",
            "Current GPU: Tesla T4\n",
            "Training model : chA_p4_cnn\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:31<00:00,  9.20s/it, Train Acc=0.9220, Val Acc=0.9517, Train Loss=0.2431, Val Loss=0.1486]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "â†’ Training model: spA_p4_cnn\n",
            "Using device: cuda\n",
            "Current GPU: Tesla T4\n",
            "Training model : spA_p4_cnn\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:11<00:00, 13.14s/it, Train Acc=0.9310, Val Acc=0.9533, Train Loss=0.2258, Val Loss=0.1448]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "â†’ Training model: big11_p4_cnn\n",
            "Using device: cuda\n",
            "Current GPU: Tesla T4\n",
            "Training model : big11_p4_cnn\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:17<00:00,  1.80s/it, Train Acc=0.9161, Val Acc=0.9583, Train Loss=0.2661, Val Loss=0.1314]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "â†’ Training model: fA_p4_allcnn\n",
            "Using device: cuda\n",
            "Current GPU: Tesla T4\n",
            "Training model : fA_p4_allcnn\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [02:01<00:00, 12.18s/it, Train Acc=0.9671, Val Acc=0.9192, Train Loss=0.2074, Val Loss=0.2976]\n"
          ]
        }
      ],
      "source": [
        "# ----- Main Training Loop -----\n",
        "for it in range(num_iterations):\n",
        "    print(f\"Iteration {it + 1}/{num_iterations}\")\n",
        "\n",
        "    for name in model_names:\n",
        "        print(f\"\\nâ†’ Training model: {name}\")\n",
        "\n",
        "        # 1. Grab hyperparams for this model\n",
        "        hp = model_hyperparameters[name]\n",
        "\n",
        "        # 2. Initialize model, criterion, optimizer, scheduler\n",
        "        model = init_model(name)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.SGD(\n",
        "            model.parameters(),\n",
        "            lr=hp.lr,\n",
        "            momentum=hp.momentum,\n",
        "            weight_decay=hp.weight_decay\n",
        "        )\n",
        "        scheduler = optim.lr_scheduler.MultiStepLR(\n",
        "            optimizer,\n",
        "            milestones=hp.milestones,\n",
        "            gamma=hp.gamma\n",
        "        )\n",
        "\n",
        "        # 3. Wrap in our Trainer (singleâ€model)\n",
        "        trainer = Trainer(\n",
        "            models={name: model},\n",
        "            optimizers=[optimizer],\n",
        "            criterions=[criterion],\n",
        "            schedulers=[scheduler],\n",
        "            log_dir=f\"{log_dir}/{name}\"\n",
        "        )\n",
        "\n",
        "        # 4. Train & validate with the modelâ€specific epoch count\n",
        "        trainer.train(\n",
        "            num_epochs=hp.epochs,\n",
        "            train_loader=train_loader,\n",
        "            val_loader=val_loader,\n",
        "        )\n",
        "\n",
        "        # 5. Evaluate on test set and record accuracy\n",
        "        test_acc = trainer.evaluate(test_loader=test_loader)[name]\n",
        "        accuracies[name].append(test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "9a805b45-7bdd-4bc9-84ca-581d7f5587f6",
      "metadata": {
        "id": "9a805b45-7bdd-4bc9-84ca-581d7f5587f6"
      },
      "outputs": [],
      "source": [
        "# ----- Final Statistics -----\n",
        "final_stats = {\n",
        "    name: {\n",
        "        \"% Test error\": (1 - float(np.mean(vals))) * 100,\n",
        "        \"% std\": float(np.std(vals)) * 100,\n",
        "        \"Num Parameters\": sum(p.numel() for p in init_model(name).parameters())\n",
        "    }\n",
        "    for name, vals in accuracies.items()\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e2827a4-7a77-4f14-b1e4-f9eb7f10fd80",
      "metadata": {
        "id": "2e2827a4-7a77-4f14-b1e4-f9eb7f10fd80"
      },
      "source": [
        "## Table generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "4dfa9492-1e4e-4e19-ad0f-7a384fa167f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dfa9492-1e4e-4e19-ad0f-7a384fa167f5",
        "outputId": "9a6ea1f3-bb91-4683-ac37-bdde9a392cc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“Š Model Accuracy Summary in CIFAR10\n",
            "\n",
            "â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
            "â”‚              â”‚   % Test error â”‚   % std â”‚   Num Parameters â”‚\n",
            "â•žâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
            "â”‚ big15_p4_cnn â”‚          47.64 â”‚   16.31 â”‚  42710           â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ chA_p4_cnn   â”‚           5.41 â”‚    0.52 â”‚  45830           â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ spA_p4_cnn   â”‚           5.58 â”‚    0.35 â”‚  46310           â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ big11_p4_cnn â”‚           5.49 â”‚    0.31 â”‚  24610           â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ fA_p4_allcnn â”‚           6.2  â”‚    1.36 â”‚      1.40012e+06 â”‚\n",
            "â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame.from_dict(final_stats, orient='index')\n",
        "df = df.round(2)\n",
        "print(\"ðŸ“Š Model Accuracy Summary in CIFAR10\\n\")\n",
        "print(tabulate(df, headers=\"keys\", tablefmt=\"fancy_grid\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
