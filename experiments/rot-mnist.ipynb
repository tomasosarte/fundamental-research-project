{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ECBMVwbIuUAu",
      "metadata": {
        "id": "ECBMVwbIuUAu"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Unzip using zipfile\n",
        "with zipfile.ZipFile('fundamental-research-project.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "VWRDooPnuWdG",
      "metadata": {
        "id": "VWRDooPnuWdG"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "shutil.rmtree('fundamental-research-project')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "035abcac-3d8c-4dd6-8722-a4e8abf2a1fe",
      "metadata": {
        "id": "035abcac-3d8c-4dd6-8722-a4e8abf2a1fe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.5 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
            "    app.start()\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n",
            "    handle._run()\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
            "    await result\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
            "    await super().execute_request(stream, ident, parent)\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3047, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3102, in _run_cell\n",
            "    result = runner(coro)\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3306, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3489, in run_ast_nodes\n",
            "    if await self.run_code(code, result, async_=asy):\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3549, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/var/folders/40/y2m0v2h9587d4pnsspl6bs6c0000gn/T/ipykernel_4842/3384419741.py\", line 17, in <module>\n",
            "    from src.trainer.trainer import Trainer\n",
            "  File \"/Users/larabastos/Desktop/uni/msc/q4/frmdl/fundamental-research-project/experiments/../src/trainer/trainer.py\", line 2, in <module>\n",
            "    from torch.utils.tensorboard import SummaryWriter\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torch/utils/tensorboard/__init__.py\", line 12, in <module>\n",
            "    from .writer import FileWriter, SummaryWriter\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torch/utils/tensorboard/writer.py\", line 19, in <module>\n",
            "    from ._embedding import get_embedding_info, make_mat, make_sprite, make_tsv, write_pbtxt\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torch/utils/tensorboard/_embedding.py\", line 10, in <module>\n",
            "    _HAS_GFILE_JOIN = hasattr(tf.io.gfile, \"join\")\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorboard/lazy.py\", line 65, in __getattr__\n",
            "    return getattr(load_once(self), attr_name)\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorboard/lazy.py\", line 97, in wrapper\n",
            "    cache[arg] = f(arg)\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorboard/lazy.py\", line 50, in load_once\n",
            "    module = load_fn()\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorboard/compat/__init__.py\", line 45, in tf\n",
            "    import tensorflow\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/__init__.py\", line 55, in <module>\n",
            "    from tensorflow._api.v2 import compat\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/_api/v2/compat/__init__.py\", line 8, in <module>\n",
            "    from tensorflow._api.v2.compat import v1\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/_api/v2/compat/v1/__init__.py\", line 30, in <module>\n",
            "    from tensorflow._api.v2.compat.v1 import compat\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py\", line 8, in <module>\n",
            "    from tensorflow._api.v2.compat.v1.compat import v1\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/_api/v2/compat/v1/compat/v1/__init__.py\", line 47, in <module>\n",
            "    from tensorflow._api.v2.compat.v1 import lite\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/_api/v2/compat/v1/lite/__init__.py\", line 9, in <module>\n",
            "    from tensorflow._api.v2.compat.v1.lite import experimental\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/_api/v2/compat/v1/lite/experimental/__init__.py\", line 8, in <module>\n",
            "    from tensorflow._api.v2.compat.v1.lite.experimental import authoring\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/_api/v2/compat/v1/lite/experimental/authoring/__init__.py\", line 8, in <module>\n",
            "    from tensorflow.lite.python.authoring.authoring import compatible # line: 263\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/lite/python/authoring/authoring.py\", line 42, in <module>\n",
            "    from tensorflow.lite.python import convert\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/lite/python/convert.py\", line 31, in <module>\n",
            "    from tensorflow.lite.python import util\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorflow/lite/python/util.py\", line 53, in <module>\n",
            "    from jax import jit as _jit\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/jax/__init__.py\", line 39, in <module>\n",
            "    from jax import config as _config_module\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/jax/config.py\", line 15, in <module>\n",
            "    from jax._src.config import config as _deprecated_config  # noqa: F401\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/jax/_src/config.py\", line 28, in <module>\n",
            "    from jax._src import lib\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/jax/_src/lib/__init__.py\", line 90, in <module>\n",
            "    import jaxlib.xla_client as xla_client\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/jaxlib/xla_client.py\", line 29, in <module>\n",
            "    from . import xla_extension as _xla\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "_ARRAY_API not found",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorboard/compat/__init__.py:42\u001b[39m, in \u001b[36mtf\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorboard\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m notf  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
            "\u001b[31mImportError\u001b[39m: cannot import name 'notf' from 'tensorboard.compat' (/Users/larabastos/miniconda3/lib/python3.12/site-packages/tensorboard/compat/__init__.py)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[31mAttributeError\u001b[39m: _ARRAY_API not found"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import List\n",
        "from tabulate import tabulate\n",
        "from dataclasses import dataclass, field\n",
        "\n",
        "# Trainer\n",
        "from src.trainer.trainer import Trainer\n",
        "\n",
        "# Models\n",
        "from src.models.chA_p4_cnn import A_Ch_P4CNN\n",
        "from src.models.spA_p4_cnn import A_Sp_P4CNN\n",
        "from src.models.fA_p4_allcnn import fA_P4AllCNNC\n",
        "from src.models.p4_allcnn import P4AllCNNC\n",
        "\n",
        "# Data Utils\n",
        "from src.datasets.rot_mnist_dataset import get_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff987c1c-1bd1-43ff-9590-68b85acaaf0b",
      "metadata": {
        "id": "ff987c1c-1bd1-43ff-9590-68b85acaaf0b"
      },
      "source": [
        "## rot-MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0e8db10c-d12b-45c5-929e-80f5d4d0ee56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "0e8db10c-d12b-45c5-929e-80f5d4d0ee56",
        "outputId": "7344d7d6-4f98-451a-e8aa-e0db84b8d584"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_loader, val_loader, test_loader = get_dataset(batch_size=128, num_workers=2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3bb54b7e-50ea-4216-8f2e-c80bad071194",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bb54b7e-50ea-4216-8f2e-c80bad071194",
        "outputId": "9310ab18-3302-477b-e9fe-f8742c7247c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "img, label = full_train[0]\n",
        "print(img.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6a8241b-b5a8-479f-bb9e-29d536497c74",
      "metadata": {
        "id": "f6a8241b-b5a8-479f-bb9e-29d536497c74"
      },
      "source": [
        "## Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4ce515d9-ec4c-4468-a77b-067e2dc3389a",
      "metadata": {
        "id": "4ce515d9-ec4c-4468-a77b-067e2dc3389a"
      },
      "outputs": [],
      "source": [
        "# ----- Helper Functions -----\n",
        "def init_model(name):\n",
        "    if name == \"chA_p4_cnn\":\n",
        "        return A_Ch_P4CNN()\n",
        "    elif name == \"spA_p4_cnn\":\n",
        "        return A_Sp_P4CNN()\n",
        "    elif name == \"fA_p4_cnn\":\n",
        "        return fA_P4AllCNNC\n",
        "    elif name == \"p4_cnn\":\n",
        "        return P4AllCNNC\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model name: {name}\")\n",
        "\n",
        "def init_optimizer(model, lr, weight_decay):\n",
        "    return optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
        "\n",
        "def init_scheduler(optimizer, milestones):\n",
        "    return optim.lr_scheduler.MultiStepLR(optimizer, milestones=[200, 250, 300], gamma=0.1)\n",
        "\n",
        "# ----- Helper Classes -----\n",
        "@dataclass\n",
        "class HyperParams:\n",
        "    lr: float\n",
        "    epochs: int\n",
        "    weight_decay: float\n",
        "    momentum: float\n",
        "    gamma: float\n",
        "    milestones: List[int] = field(default_factory=list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9f09d087-4b4d-474a-ac17-1f4d87ae7cb4",
      "metadata": {
        "id": "9f09d087-4b4d-474a-ac17-1f4d87ae7cb4"
      },
      "outputs": [],
      "source": [
        "# ----- Configuration -----\n",
        "num_iterations = 1\n",
        "log_dir = \"../logs\"\n",
        "\n",
        "model_hyperparameters = {\n",
        "    \"chA_p4_cnn\":  HyperParams(lr=0.01, epochs=3, weight_decay=1e-3, momentum=0.9, milestones=[200, 250, 300], gamma=0.1),\n",
        "    \"spA_p4_cnn\": HyperParams(lr=0.01, epochs=3, weight_decay=1e-3, momentum=0.9, milestones=[200, 250, 300], gamma=0.1),\n",
        "    \"fA_p4_cnn\": HyperParams(lr=0.01, epochs=3, weight_decay=1e-3, momentum=0.9, milestones=[200, 250, 300], gamma=0.1),\n",
        "    \"p4_cnn\":  HyperParams(lr=0.01, epochs=3, weight_decay=1e-3, momentum=0.9, milestones=[200, 250, 300], gamma=0.1)\n",
        "}\n",
        "model_names = model_hyperparameters.keys()\n",
        "accuracies = {name: [] for name in model_names}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3eec0884-5ebf-44a7-b0e7-dcf1f71216db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "3eec0884-5ebf-44a7-b0e7-dcf1f71216db",
        "outputId": "8be487c0-3f80-415b-81a0-806bd41b204e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1/1\n",
            "\n",
            "â†’ Training model: chA_p4_cnn\n",
            "Using device: cpu\n",
            "Training model : chA_p4_cnn\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epochs:   0%|          | 0/3 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "_set_worker_pids should be called only once for each _BaseDataLoaderIter.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     27\u001b[39m trainer = Trainer(\n\u001b[32m     28\u001b[39m     models={name: model},\n\u001b[32m     29\u001b[39m     optimizers=[optimizer],\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m     log_dir=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlog_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     33\u001b[39m )\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# 4. Train & validate with the modelâ€specific epoch count\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# 5. Evaluate on test set and record accuracy\u001b[39;00m\n\u001b[32m     43\u001b[39m test_acc = trainer.evaluate(test_loader=test_loader)[name]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/uni/msc/q4/frmdl/fundamental-research-project/experiments/../src/trainer/trainer.py:54\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, num_epochs, train_loader, val_loader)\u001b[39m\n\u001b[32m     51\u001b[39m model.train()\n\u001b[32m     52\u001b[39m total_loss, correct, total = \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:493\u001b[39m, in \u001b[36mDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    491\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:424\u001b[39m, in \u001b[36mDataLoader._get_iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    423\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_worker_number_rationality()\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1224\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter.__init__\u001b[39m\u001b[34m(self, loader)\u001b[39m\n\u001b[32m   1221\u001b[39m         atexit.register(_MultiProcessingDataLoaderIter._clean_up_worker, w)\n\u001b[32m   1223\u001b[39m \u001b[38;5;66;03m# .pid can be None only before process is spawned (not the case, so ignore)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1224\u001b[39m \u001b[43m_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43msignal_handling\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_set_worker_pids\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_workers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1225\u001b[39m _utils.signal_handling._set_SIGCHLD_handler()\n\u001b[32m   1226\u001b[39m \u001b[38;5;28mself\u001b[39m._worker_pids_set = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[31mValueError\u001b[39m: _set_worker_pids should be called only once for each _BaseDataLoaderIter."
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
            "        self = reduction.pickle.load(from_parent)self = reduction.pickle.load(from_parent)\n",
            "\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^^^^^  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torch/multiprocessing/reductions.py\", line 560, in rebuild_storage_filename\n",
            "^^^^\n",
            "  File \"/Users/larabastos/miniconda3/lib/python3.12/site-packages/torch/multiprocessing/reductions.py\", line 560, in rebuild_storage_filename\n",
            "    storage = torch.UntypedStorage._new_shared_filename_cpu(manager, handle, size)    \n",
            "storage = torch.UntypedStorage._new_shared_filename_cpu(manager, handle, size)\n",
            "              ^^^^^^      ^^^^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^^^^^RuntimeError^: ^Connection refused^^\n",
            "^^^^^\n",
            "RuntimeError: Connection refused\n"
          ]
        }
      ],
      "source": [
        "# ----- Main Training Loop -----\n",
        "for it in range(num_iterations):\n",
        "    print(f\"Iteration {it + 1}/{num_iterations}\")\n",
        "\n",
        "    for name in model_names:\n",
        "        print(f\"\\nâ†’ Training model: {name}\")\n",
        "\n",
        "        # 1. Grab hyperparams for this model\n",
        "        hp = model_hyperparameters[name]\n",
        "\n",
        "        # 2. Initialize model, criterion, optimizer, scheduler\n",
        "        model = init_model(name)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.SGD(\n",
        "            model.parameters(),\n",
        "            lr=hp.lr,\n",
        "            momentum=hp.momentum,\n",
        "            weight_decay=hp.weight_decay\n",
        "        )\n",
        "        scheduler = optim.lr_scheduler.MultiStepLR(\n",
        "            optimizer,\n",
        "            milestones=hp.milestones,\n",
        "            gamma=hp.gamma\n",
        "        )\n",
        "\n",
        "        # 3. Wrap in our Trainer (singleâ€model)\n",
        "        trainer = Trainer(\n",
        "            models={name: model},\n",
        "            optimizers=[optimizer],\n",
        "            criterions=[criterion],\n",
        "            schedulers=[scheduler],\n",
        "            log_dir=f\"{log_dir}/{name}\"\n",
        "        )\n",
        "\n",
        "        # 4. Train & validate with the modelâ€specific epoch count\n",
        "        trainer.train(\n",
        "            num_epochs=hp.epochs,\n",
        "            train_loader=train_loader,\n",
        "            val_loader=val_loader,\n",
        "        )\n",
        "\n",
        "        # 5. Evaluate on test set and record accuracy\n",
        "        test_acc = trainer.evaluate(test_loader=test_loader)[name]\n",
        "        accuracies[name].append(test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9a805b45-7bdd-4bc9-84ca-581d7f5587f6",
      "metadata": {
        "id": "9a805b45-7bdd-4bc9-84ca-581d7f5587f6"
      },
      "outputs": [],
      "source": [
        "# ----- Final Statistics -----\n",
        "final_stats = {\n",
        "    name: {\n",
        "        \"% Test error\": (1 - float(np.mean(vals))) * 100,\n",
        "        \"% std\": float(np.std(vals)) * 100,\n",
        "        \"Num Parameters\": sum(p.numel() for p in init_model(name).parameters())\n",
        "    }\n",
        "    for name, vals in accuracies.items()\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e2827a4-7a77-4f14-b1e4-f9eb7f10fd80",
      "metadata": {
        "id": "2e2827a4-7a77-4f14-b1e4-f9eb7f10fd80"
      },
      "source": [
        "## Table generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4dfa9492-1e4e-4e19-ad0f-7a384fa167f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dfa9492-1e4e-4e19-ad0f-7a384fa167f5",
        "outputId": "baf6a089-5501-4844-8cc1-e8b540ddbe25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Š Model Accuracy Summary in CIFAR10\n",
            "\n",
            "â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
            "â”‚              â”‚   % Test error â”‚   % std â”‚   Num Parameters â”‚\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
            "â”‚ p4_allcnn    â”‚          54.47 â”‚       0 â”‚      1.37037e+06 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ fA_p4_allcnn â”‚          62.3  â”‚       0 â”‚      1.40012e+06 â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ p4m_resnet   â”‚          53.85 â”‚       0 â”‚      2.62168e+06 â”‚\n",
            "â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame.from_dict(final_stats, orient='index')\n",
        "df = df.round(2)\n",
        "print(\"ğŸ“Š Model Accuracy Summary in CIFAR10\\n\")\n",
        "print(tabulate(df, headers=\"keys\", tablefmt=\"fancy_grid\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
